<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>NLP学习Day2：数据读取与数据分析</title>
      <link href="/2024/04/01/NLP%E5%AD%A6%E4%B9%A0Day2/"/>
      <url>/2024/04/01/NLP%E5%AD%A6%E4%B9%A0Day2/</url>
      
        <content type="html"><![CDATA[<h1 id="NLP学习Day2"><a href="#NLP学习Day2" class="headerlink" title="NLP学习Day2"></a>NLP学习Day2</h1><h2 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h2><ul><li>学习使用pandas读取赛题数据</li><li>分析赛题数据的分布规律</li></ul><h2 id="数据读取"><a href="#数据读取" class="headerlink" title="数据读取"></a>数据读取</h2><p>首先文本数据是使用csv格式进行存储。因此可以直接使用pandas完成数据读取的操作</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">train_df=pd.read_csv(<span class="string">&#x27;文本地址&#x27;</span>,sep=<span class="string">&#x27;\t&#x27;</span>,nrows=<span class="number">100</span>)</span><br></pre></td></tr></table></figure><h3 id="read-csv解析"><a href="#read-csv解析" class="headerlink" title="read_csv解析"></a>read_csv解析</h3><ul><li>读取的文件路径要改成本地的路径（相对路径或绝对路径）</li><li>分隔符<strong>sep</strong>,为每列分割的字符，设置为<strong>\t</strong>即可；</li><li>读取行数nrows,为每次读取文件的函数，是数值类型（数据集比较大）</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_df.head()</span><br></pre></td></tr></table></figure><h2 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h2><p>在数据读取操作完成之后，要对数据集进行数据分析的操作，我们希望在读取训练集数据之后得到以下结论：</p><ul><li>赛题数据中，新闻文本的长度是多少？</li><li>赛题数据的类别分布是怎么样的，哪些类别比较多？</li><li>赛题数据中，字符分布是怎么样的？</li></ul><h3 id="句子长度分析"><a href="#句子长度分析" class="headerlink" title="句子长度分析"></a>句子长度分析</h3><p>在赛题数据中每行句子的字符使用空格进行隔开，所以可以直接统计单词的个数来得到每个句子的长度</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%pylab inline</span><br><span class="line">train_df[<span class="string">&#x27;text_len&#x27;</span>]=train_df[<span class="string">&#x27;text&#x27;</span>].apply(<span class="keyword">lambda</span> x:<span class="built_in">len</span>(x,split(<span class="string">&#x27; &#x27;</span>)))</span><br><span class="line">train_df[<span class="string">&#x27;text_len&#x27;</span>].describe()</span><br></pre></td></tr></table></figure><p>下面将句子长度绘制直方图</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.hist(train_df[<span class="string">&#x27;text_len&#x27;</span>],bins=<span class="number">200</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Text char count&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Histogram of char count&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="新闻类别分布"><a href="#新闻类别分布" class="headerlink" title="新闻类别分布"></a>新闻类别分布</h2><p>对数据集的类别进行分布统计，具体统计没类新闻的样本个数。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_df[<span class="string">&#x27;label&#x27;</span>].value_counts().plot(kind=<span class="string">&#x27;bar&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;News class count&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;category&quot;</span>)</span><br></pre></td></tr></table></figure><p>在数据集中标签的对应关系如下：</p><blockquote><p>在数据集中标签的对应的关系如下：{‘科技’: 0, ‘股票’: 1, ‘体育’: 2, ‘娱乐’: 3, ‘时政’: 4, ‘社会’: 5, ‘教育’: 6, ‘财经’: 7, ‘家居’: 8, ‘游戏’: 9, ‘房产’: 10, ‘时尚’: 11, ‘彩票’: 12, ‘星座’: 13}</p></blockquote><p><strong>从统计结果看出，赛题的数据集类别分布存在较为不均匀的情况，科技类新闻最多</strong></p><h2 id="字符分布统计"><a href="#字符分布统计" class="headerlink" title="字符分布统计"></a>字符分布统计</h2><p>接下来可以统计每个字符出现的次数，首先将训练集中所有的句子进行拼接进而划分为字符，并统计每个字符的个数。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line">all_lines=<span class="string">&#x27; &#x27;</span>.join(<span class="built_in">list</span>(train_df[<span class="string">&#x27;text&#x27;</span>]))</span><br><span class="line">word_count=Counter(all_lines.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line">word_count=<span class="built_in">sorted</span>(word_count.items(),key=<span class="keyword">lambda</span> d:d[<span class="number">1</span>],reserve=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(word_count))</span><br><span class="line"><span class="built_in">print</span>(word_count[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(word_count[-<span class="number">1</span>])</span><br></pre></td></tr></table></figure><p>还可根据字在每个句子的出现情况，反推出标点符号。下面代码统计了不同字符在句子中出现的次数</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line">train_df[<span class="string">&#x27;text_unique&#x27;</span>]=train_df[<span class="string">&#x27;text&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="string">&#x27; &#x27;</span>.join(<span class="built_in">list</span>(<span class="built_in">set</span>(x.split(<span class="string">&#x27; &#x27;</span>)))))</span><br><span class="line">all_lines=<span class="string">&#x27; &#x27;</span>.join(<span class="built_in">list</span>(train_df[<span class="string">&#x27;text_unique&#x27;</span>]))</span><br><span class="line">word_count=Counter(all_lines.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line">word_count=<span class="built_in">sorted</span>(word_count.items(),key=<span class="keyword">lambda</span> d:<span class="built_in">int</span>(d[<span class="number">1</span>]),reserve=<span class="literal">True</span>)</span><br><span class="line">word_count[<span class="number">0</span>]</span><br><span class="line">word_count[<span class="number">1</span>]</span><br><span class="line">word_count[<span class="number">2</span>]</span><br></pre></td></tr></table></figure><h2 id="数据分析的结论"><a href="#数据分析的结论" class="headerlink" title="数据分析的结论"></a>数据分析的结论</h2><p>通过上述分析可得出以下结论：</p><ol><li>赛题中每个新闻包含的字符个数平均为1000个，还有一些新闻字符较长</li><li>赛题中新闻类别分布不均匀，科技类新闻样本量接近4w,星座类不到1k</li><li>赛题总共包括7000——8000个字符</li></ol><p>通过数据分析，我们还可以得出以下结论</p><ol><li>每个新闻平均字符个数较多，需要截断</li><li>由于类别不均衡，会严重影响模型的精度</li></ol><h2 id="本章小结"><a href="#本章小结" class="headerlink" title="本章小结"></a>本章小结</h2><p>对赛题数据进行读取，并新闻句子长度、类别和字符进行了可视化分析</p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>NLP学习day1：NPL实战流程</title>
      <link href="/2024/03/31/NLP%E5%AD%A6%E4%B9%A0day1/"/>
      <url>/2024/03/31/NLP%E5%AD%A6%E4%B9%A0day1/</url>
      
        <content type="html"><![CDATA[<h2 id="赛事理解"><a href="#赛事理解" class="headerlink" title="赛事理解"></a>赛事理解</h2><ul><li>通过这道赛题应了解NLP的预处理、模型构建和模型训练等知识点</li><li>本赛题以自然语言处理为背景，对新闻文本进行分类，是一个典型的字符识别问题</li></ul><h2 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h2><ul><li>理解赛题背景与赛题数据</li><li>完成赛题报名和数据下载，理解赛题的解题思路</li></ul><h2 id="赛题数据"><a href="#赛题数据" class="headerlink" title="赛题数据"></a>赛题数据</h2><ul><li>赛题数据为新闻文本，并按照字符匿名处理。整合划分出14个类别</li></ul><h2 id="数据标签"><a href="#数据标签" class="headerlink" title="数据标签"></a>数据标签</h2><hr><p>在数据集中标签的对应的关系如下：{‘科技’: 0, ‘股票’: 1, ‘体育’: 2, ‘娱乐’: 3, ‘时政’: 4, ‘社会’: 5, ‘教育’: 6, ‘财经’: 7, ‘家居’: 8, ‘游戏’: 9, ‘房产’: 10, ‘时尚’: 11, ‘彩票’: 12, ‘星座’: 13}</p><hr><h2 id="评测指标"><a href="#评测指标" class="headerlink" title="评测指标"></a>评测指标</h2><p><em><strong>为类别&#x3D;&#x3D;f1_score&#x3D;&#x3D;的均值</strong></em>，提交结果与实际测试集的类别进行对比，结果越大越好。</p><h2 id="数据读取"><a href="#数据读取" class="headerlink" title="数据读取"></a>数据读取</h2><p>使用&#x3D;&#x3D;pandas&#x3D;&#x3D;库完成读取操作，并对赛题数据进行分析</p><h2 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h2><p>赛题实质是一个文本分类问题，需要对每句的字符进行分类，但赛题给出的数据是匿名的，无法直接使用中文分词等操作，这个是赛题的难点。<br>赛题难点：需要对匿名字符进行建模，进而完成文本分类的过程，这涉及到&#x3D;&#x3D;特征提取&#x3D;&#x3D;和&#x3D;&#x3D;分类模型&#x3D;&#x3D;两部分。</p><ul><li><p>思路一：TF-IDF+机器学习分类器</p><p>直接使用TF-IDF对文本提取特征，并使用分类器进行分类。在分类器的选择上，可以使用SVM、LR、或者XGBoost。<del>看不懂qwq</del></p></li><li><p>思路二：FastText</p><p>这是一款入门款的词向量，利用Facebook提供的FastText工具，可以快速构建出分类器。<del>还是看不懂（逃）</del></p></li><li><p>思路三：WordVec + 深度学习分类器</p><p>这是进阶款的词向量，并通过构建深度学习分类完成分类。深度学习分类的网络结构可选择TextCNN、TextRNN或者BiLSTM。<del>这是啥啊</del></p></li><li><p>思路四：Bert词向量</p><p>Bert是高配款的词向量，具有强大的建模学习能力。<del>呜呜呜，不像给NLP0基础新人做的，不会只有我零基础吧:cry:</del></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>要学习的技术</title>
      <link href="/2024/03/31/%E8%A6%81%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%8A%80%E6%9C%AF/"/>
      <url>/2024/03/31/%E8%A6%81%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%8A%80%E6%9C%AF/</url>
      
        <content type="html"><![CDATA[<ol><li>个人博客主题优化，维护，并设计小功能</li><li>docker容器环境搭建并运行</li><li>NLP新闻文本分类入门+西瓜书机器学习入门</li><li>微信机器人小程序学习部署</li><li>算竞训练（一天一道1800，写题解）<br>此外<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">务须坚持学习，写博客</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
